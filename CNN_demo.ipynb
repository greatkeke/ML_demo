{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.6.0-cp312-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading torchvision-0.21.0-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sympy, torch, torchvision\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "trl 0.15.0 requires datasets>=2.21.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed sympy-1.13.1 torch-2.6.0 torchvision-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 导入所需要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Now loading CIFAR-10 dataset for Training...\n",
      "[LOG] Now loading CIFAR-10 dataset for Testing...\n",
      "[LOG] Loading CIFAR-10 dataset finished.\n"
     ]
    }
   ],
   "source": [
    "# 2. 下载CIFAR-10数据集\n",
    "# 设置图像预处理: 图像增强 + 转换为张量 + 标准化\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomCrop(32, padding=4),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# 下载训练集和测试集\n",
    "print(\"[LOG] Now loading CIFAR-10 dataset for Training...\")\n",
    "trainset = torchvision.datasets.CIFAR10(root='CIFAR10', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "print(\"[LOG] Now loading CIFAR-10 dataset for Testing...\")\n",
    "testset = torchvision.datasets.CIFAR10(root='CIFAR10', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "print(\"[LOG] Loading CIFAR-10 dataset finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Now loading model RestNet-18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KEKE\\miniconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\KEKE\\miniconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Loading model ResNet-18 finished.\n"
     ]
    }
   ],
   "source": [
    "# 3. 使用ResNet-18作为预训练网络\n",
    "# 下载预训练的ResNet-18模型\n",
    "print(\"[LOG] Now loading model RestNet-18...\")\n",
    "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "print(\"[LOG] Loading model ResNet-18 finished.\")\n",
    "# 由于CIFAR-10有10个类，我们需要调整ResNet的最后一个全连接层\n",
    "num_classes = 10\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Using device:  xpu\n"
     ]
    }
   ],
   "source": [
    "import torch.mps\n",
    "import torch.xpu\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "if(torch.cuda.is_available()):\n",
    "    device = 'cuda:0'\n",
    "if(torch.xpu.is_available()):\n",
    "    device = 'xpu'\n",
    "if(torch.mps.is_available()):\n",
    "    device = 'mps'\n",
    "print(\"[LOG] Using device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 微调预训练的CNN网络\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet18.parameters(), lr=0.001, momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Start training...\n",
      "[1,   200] loss: 1.575\n",
      "[1,   400] loss: 1.160\n",
      "[1,   600] loss: 1.021\n",
      "[2,   200] loss: 0.880\n",
      "[2,   400] loss: 0.843\n",
      "[2,   600] loss: 0.815\n",
      "[3,   200] loss: 0.738\n",
      "[3,   400] loss: 0.715\n",
      "[3,   600] loss: 0.728\n",
      "[4,   200] loss: 0.642\n",
      "[4,   400] loss: 0.657\n",
      "[4,   600] loss: 0.641\n",
      "[5,   200] loss: 0.582\n",
      "[5,   400] loss: 0.607\n",
      "[5,   600] loss: 0.605\n",
      "[6,   200] loss: 0.570\n",
      "[6,   400] loss: 0.565\n",
      "[6,   600] loss: 0.569\n",
      "[7,   200] loss: 0.526\n",
      "[7,   400] loss: 0.528\n",
      "[7,   600] loss: 0.534\n",
      "[8,   200] loss: 0.493\n",
      "[8,   400] loss: 0.502\n",
      "[8,   600] loss: 0.498\n",
      "[9,   200] loss: 0.480\n",
      "[9,   400] loss: 0.481\n",
      "[9,   600] loss: 0.471\n",
      "[10,   200] loss: 0.452\n",
      "[10,   400] loss: 0.460\n",
      "[10,   600] loss: 0.465\n",
      "[LOG] Training finished\n"
     ]
    }
   ],
   "source": [
    "# 迁移到GPU上（如果有的话）\n",
    "resnet18.to(device)\n",
    "# 训练网络\n",
    "print(\"[LOG] Start training...\")\n",
    "for epoch in range(10):  # 就演示训练10个epochs\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取输入数据\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # 清零参数梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 前向 + 反向 + 优化\n",
    "        outputs = resnet18(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:  # 每200批次打印一次\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "print('[LOG] Training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Native API failed. Native API returns: 2147483646 (UR_RESULT_ERROR_UNKNOWN)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m testloader:\n\u001b[1;32m----> 6\u001b[0m         images, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m resnet18(images)\n\u001b[0;32m      8\u001b[0m         _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Native API failed. Native API returns: 2147483646 (UR_RESULT_ERROR_UNKNOWN)"
     ]
    }
   ],
   "source": [
    "# 5. 测试网络性能\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = resnet18(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('[LOG] Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
